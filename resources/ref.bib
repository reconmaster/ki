
@article{sawall_model-based_2017,
  title = {Model-Based Sphere Localization ({{MBSL}}) in x-Ray Projections},
  volume = {62},
  issn = {0031-9155},
  abstract = {The detection of spherical markers in x-ray projections is an important task in a variety of applications, e.g. geometric calibration and detector distortion correction. Therein, the projection of the sphere center on the detector is of particular interest as the used spherical beads are no ideal point-like objects. Only few methods have been proposed to estimate this respective position on the detector with sufficient accuracy and surrogate positions, e.g. the center of gravity, are used, impairing the results of subsequent algorithms. We propose to estimate the projection of the sphere center on the detector using a simulation-based method matching an artificial projection to the actual measurement. The proposed algorithm intrinsically corrects for all polychromatic effects included in the measurement and absent in the simulation by a polynomial which is estimated simultaneously. Furthermore, neither the acquisition geometry nor any object properties besides the fact that the object is of spherical shape need to be known to find the center of the bead. It is shown by simulations that the algorithm estimates the center projection with an error of less than \#\#IMG\#\# [http://ej.iop.org/images/0031-9155/62/16/6486/pmbaa7a96ieqn001.gif] \$1\%\$ of the detector pixel size in case of realistic noise levels and that the method is robust to the sphere material, sphere size, and acquisition parameters. A comparison to three reference methods using simulations and measurements indicates that the proposed method is an order of magnitude more accurate compared to these algorithms. The proposed method is an accurate algorithm to estimate the center of spherical markers in CT projections in the presence of polychromatic effects and noise.},
  language = {en},
  number = {16},
  journal = {Physics in Medicine \& Biology},
  doi = {10.1088/1361-6560/aa7a96},
  author = {Sawall, Stefan and Maier, Joscha and Leinweber, Carsten and Funck, Carsten and Kuntz, Jan and Kachelrie{\ss}, Marc},
  year = {2017},
  keywords = {read,\#B},
  pages = {6486},
  file = {/home/reconmaster/Zotero/storage/4LDXSGSV/Sawall et al. - 2017 - Model-based sphere localization (MBSL) in x-ray pr.pdf}
}

@article{wang_image_2004,
  title = {Image Quality Assessment: From Error Visibility to Structural Similarity},
  volume = {13},
  issn = {1057-7149},
  shorttitle = {Image Quality Assessment},
  abstract = {Objective methods for assessing perceptual image quality traditionally attempted to quantify the visibility of errors (differences) between a distorted image and a reference image using a variety of known properties of the human visual system. Under the assumption that human visual perception is highly adapted for extracting structural information from a scene, we introduce an alternative complementary framework for quality assessment based on the degradation of structural information. As a specific example of this concept, we develop a structural similarity index and demonstrate its promise through a set of intuitive examples, as well as comparison to both subjective ratings and state-of-the-art objective methods on a database of images compressed with JPEG and JPEG2000. A MATLAB implementation of the proposed algorithm is available online at http://www.cns.nyu.edu/{$\sim$}lcv/ssim/.},
  number = {4},
  journal = {IEEE Transactions on Image Processing},
  doi = {10.1109/TIP.2003.819861},
  author = {Wang, Zhou and Bovik, A.C. and Sheikh, H.R. and Simoncelli, E.P.},
  year = {2004},
  keywords = {\#A,read,Algorithms,Humans,image coding,Image quality,Visual system,Models; Statistical,Image Interpretation; Computer-Assisted,Reproducibility of Results,Signal Processing; Computer-Assisted,Sensitivity and Specificity,Image Enhancement,data compression,Data Interpretation; Statistical,Data mining,Degradation,distorted image,error sensitivity,error visibility,human visual perception,human visual system,Hypermedia,image compression,image database,Indexes,Information Storage and Retrieval,JPEG,JPEG2000,Layout,Pattern Recognition; Automated,perceptual image quality assessment,Quality assessment,Quality Control,reference image,structural information,structural similarity index,Subtraction Technique,transform coding,visual perception},
  pages = {600-612},
  file = {/home/reconmaster/cloud/medical_physics/zotero/wang_image_2004.pdf;/home/reconmaster/Zotero/storage/UHZT2HW3/articleDetails.html}
}

@article{tamura_textural_1978,
  title = {Textural {{Features Corresponding}} to {{Visual Perception}}},
  volume = {8},
  issn = {0018-9472},
  abstract = {Textural features corresponding to human visual perception are very useful for optimum feature selection and texture analyzer design. We approximated in computational form six basic textural features, namely, coarseness, contrast, directionality, line-likeness, regularity, and roughness. In comparison with psychological measurements for human subjects, the computational measures gave good correspondences in rank correlation of 16 typical texture patterns. Similarity measurements using these features were attempted. The discrepancies between human vision and computerized techniques that we encountered in this study indicate fundamental problems in digital analysis of textures. Some of them could be overcome by analyzing their causes and using more sophisticated techniques.},
  number = {6},
  journal = {IEEE Transactions on Systems, Man and Cybernetics},
  doi = {10.1109/TSMC.1978.4309999},
  author = {Tamura, Hideyuki and Mori, Shunji and Yamawaki, Takashi},
  year = {1978},
  keywords = {Humans,Image analysis,Image edge detection,\#B,visual perception,Detectors,Anthropometry,Image segmentation,Laboratories,Magnetooptic recording,Psychology},
  pages = {460-473},
  file = {/home/reconmaster/cloud/medical_physics/zotero/tamura_textural_1978.pdf;/home/reconmaster/Zotero/storage/RWWURVZ5/articleDetails.html}
}

@inproceedings{wei_effective_2007,
  title = {Effective {{Extraction}} of {{Gabor Features}} for {{Adaptive Mammogram Retrieval}}},
  abstract = {Breast cancer is one of the most common diseases among women. Content-based mammogram retrieval has been proposed to aid various medical procedures. To develop a content-based mammogram retrieval system, textural feature extraction is one of the crucial requirements. This study proposes a Gabor filtering method for the extraction of textural features, which firstly performs Gabor filtering on the underlying image, applies the physical properties of a probability wave to probability transformation and then computes features to describe the textural pattern of the mammogram. This study also proposes an adaptive strategy for feature selection, filter selection and feature weighting, which utilizes a user's relevance feedback to reduce the redundancy in the representation and incorporates the user's information needs in image retrieval. Experimental results show that hypothesis tests can effectively find discriminated features and this retrieval system can improve its performance through just a few rounds of relevance feedback.},
  booktitle = {2007 {{IEEE International Conference}} on {{Multimedia}} and {{Expo}}},
  doi = {10.1109/ICME.2007.4284947},
  author = {Wei, Chia-Hung and Li, Yue and Li, Chang-Tsun},
  year = {2007},
  keywords = {medical image processing,cancer,\#C,mammography,Breast cancer,Biomedical imaging,image texture,Filtering,Adaptive filters,adaptive mammogram retrieval,Content based retrieval,content-based mammogram retrieval,Diseases,feature extraction,feature selection,feature weighting,Feedback,filter selection,filtering theory,Gabor features extraction,Gabor filtering method,Gabor filters,image retrieval,Physics computing,probability transformation,relevance feedback,textural feature extraction},
  pages = {1503-1506},
  file = {/home/reconmaster/cloud/medical_physics/zotero/wei_effective_2007.pdf;/home/reconmaster/Zotero/storage/KES83CBJ/articleDetails.html}
}

@article{manjunath_new_1996,
  title = {A New Approach to Image Feature Detection with Applications},
  volume = {29},
  issn = {0031-3203},
  abstract = {Image feature detection is a fundamental issue in many intermediate level vision problems such as stereo, motion correspondence, image registration and object recognition. In this paper we present an approach to feature detection based on a scale-interaction model. This feature detector is responsive to short lines, line endings, corners and other such sharp changes in curvature. We provide extensive experimental results to demonstrate its potential applications to several image analysis problems.},
  number = {4},
  journal = {Pattern Recognition},
  doi = {10.1016/0031-3203(95)00115-8},
  author = {Manjunath, B. S. and Shekhar, C. and Chellappa, R.},
  month = apr,
  year = {1996},
  keywords = {image registration,\#B,Gabor filters,face recognition,Feature detection,Motion tracking},
  pages = {627-640},
  file = {/home/reconmaster/cloud/medical_physics/zotero/manjunath_new_1996.pdf;/home/reconmaster/Zotero/storage/VN2SBMVP/0031320395001158.html}
}

@inproceedings{manjunath_feature_1992,
  title = {A Feature Based Approach to Face Recognition},
  abstract = {A feature-based approach to face recognition in which the features are derived from the intensity data without assuming any knowledge of the face structure is presented. The feature extraction model is biologically motivated, and the locations of the features often correspond to salient facial features such as the eyes, nose, etc. Topological graphs are used to represent relations between features, and a simple deterministic graph-matching scheme that exploits the basic structure is used to recognize familiar faces from a database. Each of the stages in the system can be fully implemented in parallel to achieve real-time recognition. Experimental results for a 128\texttimes{}128 image with very little noise are evaluated},
  booktitle = {, 1992 {{IEEE Computer Society Conference}} on {{Computer Vision}} and {{Pattern Recognition}}, 1992. {{Proceedings CVPR}} '92},
  doi = {10.1109/CVPR.1992.223162},
  author = {Manjunath, B.S. and Chellappa, R. and {Von der Malsburg}, C.},
  year = {1992},
  keywords = {Humans,\#B,Visual system,feature extraction,face recognition,Biological system modeling,database,deterministic graph-matching scheme,eyes,Face detection,feature based approach,feature extraction model,intensity data,Mouth,nose,real-time recognition,Spatial databases,Visual databases},
  pages = {373-378},
  file = {/home/reconmaster/cloud/medical_physics/zotero/manjunath_feature_1992.pdf;/home/reconmaster/Zotero/storage/9PBPF6EJ/articleDetails.html}
}

@article{liu_gabor_2002,
  title = {Gabor Feature Based Classification Using the Enhanced Fisher Linear Discriminant Model for Face Recognition},
  volume = {11},
  issn = {1057-7149},
  abstract = {This paper introduces a novel Gabor-Fisher (1936) classifier (GFC) for face recognition. The GFC method, which is robust to changes in illumination and facial expression, applies the enhanced Fisher linear discriminant model (EFM) to an augmented Gabor feature vector derived from the Gabor wavelet representation of face images. The novelty of this paper comes from (1) the derivation of an augmented Gabor feature vector, whose dimensionality is further reduced using the EFM by considering both data compression and recognition (generalization) performance; (2) the development of a Gabor-Fisher classifier for multi-class problems; and (3) extensive performance evaluation studies. In particular, we performed comparative studies of different similarity measures applied to various classifiers. We also performed comparative experimental studies of various face recognition schemes, including our novel GFC method, the Gabor wavelet method, the eigenfaces method, the Fisherfaces method, the EFM method, the combination of Gabor and the eigenfaces method, and the combination of Gabor and the Fisherfaces method. The feasibility of the new GFC method has been successfully tested on face recognition using 600 FERET frontal face images corresponding to 200 subjects, which were acquired under variable illumination and facial expressions. The novel GFC method achieves 100\% accuracy on face recognition using only 62 features},
  number = {4},
  journal = {IEEE Transactions on Image Processing},
  doi = {10.1109/TIP.2002.999679},
  author = {Liu, Chengjun and Wechsler, H.},
  year = {2002},
  keywords = {Performance evaluation,\#C,Testing,data compression,Vectors,feature extraction,face recognition,augmented Gabor feature vector,Computer science,eigenfaces method,eigenvalues and eigenfunctions,enhanced Fisher linear discriminant model,facial expression,Fisherfaces method,frontal face images,Gabor feature based classification,Gabor wavelet method,Gabor wavelet representation,Illumination,Image classification,image representation,Kernel,Lighting,multi-class problems,Particle measurements,Robustness,similarity measures,wavelet transforms},
  pages = {467-476},
  file = {/home/reconmaster/cloud/medical_physics/zotero/liu_gabor_2002.pdf;/home/reconmaster/Zotero/storage/E8XWHPDM/articleDetails.html}
}

@article{zheng_computational_1993,
  title = {A Computational Vision Approach to Image Registration},
  volume = {2},
  issn = {1057-7149},
  abstract = {A computational vision approach is presented for the estimation of 2-D translation, rotation, and scale from two partially overlapping images. The approach results in a fast method that produces good results even when large rotation and translation have occurred between the two frames and the images are devoid of significant features. An illuminant direction estimation method is first used to obtain an initial estimation of camera rotation. A small number of feature points are then located, using a Gabor wavelet model for detecting local curvature discontinuities. An initial estimate of scale and translation is obtained by pairwise matching of the feature points detected from both frames. Finally, hierarchical feature matching is performed to obtain an accurate estimate of translation, rotation and scale. A method for error analysis of matching results is also presented. Experiments with synthetic and real images show that this algorithm yields accurate results when the scale of the images differ by up to 10\%, the overlap between the two frames is as small as 23\%, and the camera rotation between the two frames is significant. Experimental results and applications are presented},
  number = {3},
  journal = {IEEE Transactions on Image Processing},
  doi = {10.1109/83.236535},
  author = {Zheng, Qinfen and Chellappa, R.},
  year = {1993},
  keywords = {image registration,\#B,image processing,Cameras,computer vision,2-D translation,Azimuth,camera rotation,computational vision,error analysis,Gabor wavelet model,hierarchical feature matching,illuminant direction estimation method,Mars,Motion estimation,Motion measurement,pairwise matching,rotation,scale,Surface topography,Velocity measurement,Wind speed},
  pages = {311-326},
  file = {/home/reconmaster/cloud/medical_physics/zotero/zheng_computational_1993.pdf;/home/reconmaster/Zotero/storage/MC4Z9AF2/articleDetails.html}
}

@article{jain_unsupervised_1991,
  title = {Unsupervised Texture Segmentation Using {{Gabor}} Filters},
  volume = {24},
  issn = {0031-3203},
  abstract = {This paper presents a texture segmentation algorithm inspired by the multi-channel filtering theory for visual information processing in the early stages of human visual system. The channels are characterized by a bank of Gabor filters that nearly uniformly covers the spatial-frequency domain, and a systematic filter selection scheme is proposed, which is based on reconstruction of the input image from the filtered images. Texture features are obtained by subjecting each (selected) filtered image to a nonlinear transformation and computing a measure of ``energy'' in a window around each pixel. A square-error clustering algorithm is then used to integrate the feature images and produce a segmentation. A simple procedure to incorporate spatial information in the clustering process is proposed. A relative index is used to estimate the ``true'' number of texture categories.},
  number = {12},
  journal = {Pattern Recognition},
  doi = {10.1016/0031-3203(91)90143-S},
  author = {Jain, Anil K. and Farrokhnia, Farshid},
  year = {1991},
  keywords = {\#B,Gabor filters,Clustering,Clustering index,Multi-channel filtering,Texture segmentation,Wavelet transform},
  pages = {1167-1186},
  file = {/home/reconmaster/cloud/medical_physics/zotero/jain_unsupervised_1991.pdf;/home/reconmaster/Zotero/storage/Z8SDUVSP/003132039190143S.html}
}

@article{weldon_efficient_1996,
  title = {Efficient {{Gabor}} Filter Design for Texture Segmentation},
  volume = {29},
  issn = {0031-3203},
  abstract = {Gabor filters have been successfully applied to a broad range of image processing tasks. The present paper considers the design of a single filter to segment a two-texture image. A new efficient algorithm for Gabor-filter design is presented, along with methods for estimating filter output statistics. The algorithm draws upon previous results that showed that the output of a Gabor-filtered texture is modeled well by a Rician distribution. A measure of the total output power is used to select the center frequency of the filter and is used to estimate the Rician statistics of the Gabor-filtered image. The method is further generalized to include the statistics of postfiltered outputs that are generated by a Gaussian filtering operation following the Gabor filter. The new method typically requires an order of magnitude less computation to design a filter than a previously proposed method. Experimental results demonstrate the efficacy of the method.},
  number = {12},
  journal = {Pattern Recognition},
  doi = {10.1016/S0031-3203(96)00047-7},
  author = {Weldon, Thomas P. and Higgins, William E. and Dunn, Dennis F.},
  month = dec,
  year = {1996},
  keywords = {\#B,Image segmentation,Gabor filters,Texture segmentation,Image statistics,Rician statistics,Texture,Texture analysis},
  pages = {2005-2015},
  file = {/home/reconmaster/cloud/medical_physics/zotero/weldon_efficient_1996.pdf;/home/reconmaster/Zotero/storage/IUTNR4TW/S0031320396000477.html}
}

@article{mcnitt-gray_effects_1999,
  title = {The Effects of Co-Occurrence Matrix Based Texture Parameters on the Classification of Solitary Pulmonary Nodules Imaged on Computed Tomography},
  volume = {23},
  issn = {0895-6111},
  abstract = {In this project, patients with a solitary pulmonary nodule, were imaged using high resolution computed tomography. Quantitative measures of texture were extracted from these images using co-occurrence matrices. These matrices were formed with different combinations of gray level quantization, distance between pixels and angles. The derived measures were input to a linear discriminant classifier to predict the classification (benign or malignant) of each nodule. Using a relative quantization scheme with eight levels, four features yielded an area under the ROC curve (Az) of 0.992; 93.8\% (30/32) of cases were correctly classified when training and testing on the same cases; while 90.6\% (29/32) were correctly classified when jackknifing was used.},
  number = {6},
  journal = {Computerized Medical Imaging and Graphics},
  doi = {10.1016/S0895-6111(99)00033-6},
  author = {{McNitt-Gray}, M. F. and Wyckoff, N. and Sayre, J. W. and Goldin, J. G. and Aberle, D. R.},
  month = dec,
  year = {1999},
  keywords = {Computed tomography,Medical imaging,\#B,image processing,Texture,Computer-aided diagnosis,lung,Pattern classification,Solitary pulmonary nodule},
  pages = {339-348},
  file = {/home/reconmaster/cloud/medical_physics/zotero/mcnitt-gray_effects_1999.pdf;/home/reconmaster/Zotero/storage/576F2RM2/S0895611199000336.html}
}

@article{ranjanomennahary_comparison_2010,
  title = {Comparison of Radiograph-Based Texture Analysis and Bone Mineral Density with Three-Dimensional Microarchitecture of Trabecular Bone},
  volume = {38},
  issn = {0094-2405},
  abstract = {Purpose: Hip fracture is a serious health problem and textural methods are being developed to assess bone quality. The authors aimed to perform textural analysis at femur on high-resolution digital radiographs compared to three-dimensional (3D) microarchitecture comparatively to bone mineral density. Methods: Sixteen cadaveric femurs were imaged with an x-ray device using a C-MOS sensor. One 17 mm square region of interest (ROI) was selected in the femoral head (FH) and one in the great trochanter (GT). Two-dimensional (2D) textural features from the co-occurrence matrices were extracted. Site-matched measurements of bone mineral density were performed. Inside each ROI, a 16 mm diameter core was extracted. Apparent density ( D app ) and bone volume proportion ( BV / TV Arch ) were measured from a defatted bone core using Archimedes' principle. Microcomputed tomographyimages of the entire length of the core were obtained (Skyscan 1072\textregistered{}) at 19.8 {$\mu$} m of resolution and usual 3D morphometric parameters were computed on the binary volume after calibration from BV / TV Arch . Then, bone surface/bone volume, trabecular thickness, trabecular separation, and trabecular number were obtained by direct methods without model assumption and the structure model index was calculated. Results: In univariate analysis, the correlation coefficients between 2D textural features and 3D morphological parameters reached 0.83 at the FH and 0.79 at the GT. In multivariate canonical correlation analysis, coefficients of the first component reached 0.95 at the FH and 0.88 at the GT. Conclusions: Digital radiographs, widely available and economically viable, are an alternative method for evaluating bone microarchitectural structure.},
  number = {1},
  journal = {Medical Physics},
  doi = {10.1118/1.3528125},
  author = {Ranjanomennahary, P. and Ghalila, S. Sevestre and Malouche, D. and Marchadier, A. and Rachidi, M. and Benhamou, Cl and Chappard, C.},
  month = dec,
  year = {2010},
  keywords = {Radiography,image reconstruction,Computed tomography,X-ray imaging,Medical image reconstruction,Medical imaging,Statistical analysis,Medical X-ray imaging,\#B,image sensors,Multivariate analysis},
  pages = {420-428},
  file = {/home/reconmaster/cloud/medical_physics/zotero/ranjanomennahary_comparison_2010.pdf;/home/reconmaster/Zotero/storage/5E6MQA5B/1.html}
}

@article{haralick_textural_1973,
  title = {Textural {{Features}} for {{Image Classification}}},
  volume = {SMC-3},
  issn = {0018-9472},
  abstract = {Texture is one of the important characteristics used in identifying objects or regions of interest in an image, whether the image be a photomicrograph, an aerial photograph, or a satellite image. This paper describes some easily computable textural features based on gray-tone spatial dependancies, and illustrates their application in category-identification tasks of three different kinds of image data: photomicrographs of five kinds of sandstones, 1:20 000 panchromatic aerial photographs of eight land-use categories, and Earth Resources Technology Satellite (ERTS) multispecial imagery containing seven land-use categories. We use two kinds of decision rules: one for which the decision regions are convex polyhedra (a piecewise linear decision rule), and one for which the decision regions are rectangular parallelpipeds (a min-max decision rule). In each experiment the data set was divided into two parts, a training set and a test set. Test set identification accuracy is 89 percent for the photomicrographs, 82 percent for the aerial photographic imagery, and 83 percent for the satellite imagery. These results indicate that the easily computable textural features probably have a general applicability for a wide variety of image-classification applications.},
  number = {6},
  journal = {IEEE Transactions on Systems, Man and Cybernetics},
  doi = {10.1109/TSMC.1973.4309314},
  author = {Haralick, R.M. and Shanmugam, K. and Dinstein, Its'Hak},
  year = {1973},
  keywords = {image resolution,Humans,\#B,Testing,Spatial resolution,Image classification,Application software,Crops,Earth,Piecewise linear techniques,Satellites},
  pages = {610-621},
  file = {/home/reconmaster/cloud/medical_physics/zotero/haralick_textural_1973.pdf;/home/reconmaster/Zotero/storage/39DTMKXP/articleDetails.html}
}

@article{coelho_mahotas:_2013,
  title = {Mahotas: {{Open}} Source Software for Scriptable Computer Vision},
  volume = {1},
  copyright = {Authors who publish with this journal agree to the following terms:    Authors retain copyright and grant the journal right of first publication with the work simultaneously licensed under a  Creative Commons Attribution License  that allows others to share the work with an acknowledgement of the work's authorship and initial publication in this journal.  Authors are able to enter into separate, additional contractual arrangements for the non-exclusive distribution of the journal's published version of the work (e.g., post it to an institutional repository or publish it in a book), with an acknowledgement of its initial publication in this journal.  Authors are permitted and encouraged to post their work online (e.g., in institutional repositories or on their website) prior to and during the submission process, as it can lead to productive exchanges, as well as earlier and greater citation of published work (See  The Effect of Open Access ).  All third-party images reproduced on this journal are shared under Educational Fair Use. For more information on  Educational Fair Use , please see  this useful checklist prepared by Columbia University Libraries .   All copyright  of third-party content posted here for research purposes belongs to its original owners.  Unless otherwise stated all references to characters and comic art presented on this journal are \textcopyright, \textregistered{} or \texttrademark{} of their respective owners. No challenge to any owner's rights is intended or should be inferred.},
  issn = {2049-9647},
  shorttitle = {Mahotas},
  abstract = {Mahotas is a computer vision library for Python. It contains traditional image processing functionality such as filtering and morphological operations as well as more modern computer vision functions for feature computation, including interest point detection and local descriptors.
The interface is in Python, a dynamic programming language, which is appropriate for fast development, but the algorithms are implemented in C++ and are tuned for speed. The library is designed to fit in with the scientific software ecosystem in this language and can leverage the existing infrastructure developed in that language.
Mahotas is released under a liberal open source license (MIT License) and is available from http://github.com/luispedro/mahotas and from the Python Package Index (http://pypi.python.org/pypi/mahotas). Tutorials and full API documentation are available online at http://mahotas.readthedocs.org/.},
  language = {en},
  number = {1},
  journal = {Journal of Open Research Software},
  doi = {10.5334/jors.ac},
  author = {Coelho, Luis Pedro},
  month = jul,
  year = {2013},
  keywords = {\#B},
  file = {/home/reconmaster/cloud/medical_physics/zotero/coelho_mahotas_2013.pdf;/home/reconmaster/Zotero/storage/CWAKZMGX/jors.html}
}

@article{van_der_walt_scikit-image:_2014,
  title = {Scikit-Image: Image Processing in {{Python}}},
  volume = {2},
  issn = {2167-8359},
  shorttitle = {Scikit-Image},
  language = {en},
  journal = {PeerJ},
  doi = {10.7717/peerj.453},
  author = {{van der Walt}, St{\'e}fan and Sch{\"o}nberger, Johannes L. and {Nunez-Iglesias}, Juan and Boulogne, Fran{\c c}ois and Warner, Joshua D. and Yager, Neil and Gouillart, Emmanuelle and Yu, Tony},
  month = jun,
  year = {2014},
  keywords = {\#A,read},
  pages = {e453},
  file = {/home/reconmaster/cloud/medical_physics/zotero/van_der_walt_scikit-image_2014.pdf}
}

@article{poldrack_region_2007,
  title = {Region of Interest Analysis for {{fMRI}}},
  volume = {2},
  issn = {1749-5016},
  abstract = {A common approach to the analysis of fMRI data involves the extraction of signal from specified regions of interest (or ROI's). Three approaches to ROI analysis are described, and the strengths and assumptions of each method are outlined.},
  number = {1},
  journal = {Social cognitive and affective neuroscience},
  doi = {10.1093/scan/nsm006},
  author = {Poldrack, Russell A.},
  month = mar,
  year = {2007},
  keywords = {\#B},
  pages = {67-70},
  file = {/home/reconmaster/cloud/medical_physics/zotero/poldrack_region_2007.pdf},
  pmid = {18985121},
  pmcid = {PMC2555436}
}

@article{kaifosh_sima:_2014,
  title = {{{SIMA}}: {{Python}} Software for Analysis of Dynamic Fluorescence Imaging Data},
  volume = {8},
  issn = {1662-5196},
  shorttitle = {{{SIMA}}},
  abstract = {Fluorescence imaging is a powerful method for monitoring dynamic signals in the nervous system. However, analysis of dynamic fluorescence imaging data remains burdensome, in part due to the shortage of available software tools. To address this need, we have developed SIMA, an open source Python package that facilitates common analysis tasks related to fluorescence imaging. Functionality of this package includes correction of motion artifacts occurring during in vivo imaging with laser-scanning microscopy, segmentation of imaged fields into regions of interest (ROIs), and extraction of signals from the segmented ROIs. We have also developed a graphical user interface (GUI) for manual editing of the automatically segmented ROIs and automated registration of ROIs across multiple imaging datasets. This software has been designed with flexibility in mind to allow for future extension with different analysis methods and potential integration with other packages. Software, documentation, and source code for the SIMA package and ROI Buddy GUI are freely available at http://www.losonczylab.org/sima/.},
  journal = {Frontiers in Neuroinformatics},
  doi = {10.3389/fninf.2014.00080},
  author = {Kaifosh, Patrick and Zaremba, Jeffrey D. and Danielson, Nathan B. and Losonczy, Attila},
  month = sep,
  year = {2014},
  keywords = {read,\#B},
  file = {/home/reconmaster/cloud/medical_physics/zotero/kaifosh_sima_2014.pdf},
  pmid = {25295002},
  pmcid = {PMC4172099}
}

@article{maes_multimodality_1997,
  title = {Multimodality Image Registration by Maximization of Mutual Information},
  volume = {16},
  issn = {0278-0062},
  abstract = {A new approach to the problem of multimodality medical image registration is proposed, using a basic concept from information theory, mutual information (MI), or relative entropy, as a new matching criterion. The method presented in this paper applies MI to measure the statistical dependence or information redundancy between the image intensities of corresponding voxels in both images, which is assumed to be maximal if the images are geometrically aligned. Maximization of MI is a very general and powerful criterion, because no assumptions are made regarding the nature of this dependence and no limiting constraints are imposed on the image content of the modalities involved. The accuracy of the MI criterion is validated for rigid body registration of computed tomography (CT), magnetic resonance (MR), and photon emission tomography (PET) images by comparison with the stereotactic registration solution, while robustness is evaluated with respect to implementation issues, such as interpolation and optimization, and image content, including partial overlap and image degradation. Our results demonstrate that subvoxel accuracy with respect to the stereotactic reference solution can be achieved completely automatically and without any prior segmentation, feature extraction, or other preprocessing steps which makes this method very well suited for clinical applications.},
  number = {2},
  journal = {IEEE Transactions on Medical Imaging},
  doi = {10.1109/42.563664},
  author = {Maes, F. and Collignon, A. and Vandermeulen, D. and Marchal, G. and Suetens, P.},
  month = apr,
  year = {1997},
  keywords = {\#A,read,Algorithms,Image Processing; Computer-Assisted,medical image processing,Computed tomography,computerised tomography,Humans,Entropy,Positron emission tomography,single photon emission computed tomography,Statistical analysis,optimisation,image registration,Diagnostic Imaging,interpolation,Biomedical imaging,Robustness,voxels,Optimization,Brain,biomedical NMR,clinical applications,image content,image degradation,image intensities,image matching,information redundancy,information theory,Magnetic resonance,matching criterion,maximization,medical image registration,multimodality image registration,mutual information,partial overlap,PET images,photon emission tomography,relative entropy,rigid body registration,statistical dependence,stereotactic reference solution,stereotactic registration solution,subvoxel accuracy},
  pages = {187-198},
  file = {/home/reconmaster/cloud/medical_physics/zotero/maes_multimodality_1997.pdf;/home/reconmaster/Zotero/storage/9ZBSBSVX/articleDetails.html}
}

@article{metz_basic_1978,
  title = {Basic Principles of {{ROC}} Analysis},
  volume = {8},
  issn = {0001-2998},
  abstract = {The limitations of diagnostic ``accuracy'' as a measure of decision performance require introduction of the concepts of the ``sensitivity'' and ``specificity'' of a diagnostic test. These measures and the related indices, ``true positive fraction'' and ``false positive fraction'', are more meaningful than ``accuracy'', yet do not provide a unique description of diagnostic performance because they depend on the arbitrary selection of a decision threshold. The receiver operating characteristic (ROC) curve is shown to be a simple yet complete empirical description of this decision threshold effect, indicating all possible combinations of the relative frequencies of the various kinds of correct and incorrect decisions. Practical experimental techniques for measuring ROC curves are described, and the issues of case selection and curve-fitting are discussed briefly. Possible generalizations of conventional ROC analysis to account for decision performance in complex diagnostic tasks are indicated. ROC analysis is shown to be related in a direct and natural way to cost/benefit analysis of diagnostic decision making. The concepts of ``average diagnostic cost'' and ``average net benefit'' are developed and used to identify the optimal compromise among various kinds of diagnostic error. Finally, the way in which ROC analysis can be employed to optimize diagnostic strategies is suggested.},
  number = {4},
  journal = {Seminars in Nuclear Medicine},
  doi = {10.1016/S0001-2998(78)80014-2},
  author = {Metz, Charles E.},
  month = oct,
  year = {1978},
  keywords = {\#A},
  pages = {283-298},
  file = {/home/reconmaster/cloud/medical_physics/zotero/metz_basic_1978.pdf;/home/reconmaster/Zotero/storage/D9T9IPZQ/S0001299878800142.html}
}

@misc{peng_detect_2007,
  title = {Detect Circles with Various Radii in Grayscale Image via {{Hough Transform}} - {{File Exchange}} - {{MATLAB Central}}},
  abstract = {Detect circular shapes in a grayscale image. Resolve their center positions and radii.},
  howpublished = {http://www.mathworks.com/matlabcentral/fileexchange/file\_infos/9168-detect-circles-with-various-radii-in-grayscale-image-via-hough-transform},
  author = {Peng, Tao},
  year = {2007},
  keywords = {\#A,file exchange,link exchange,matlab and simulink community,matlab answers,matlab blog,matlab central,matlab community,newsgroup access,simulink blog},
  file = {/home/reconmaster/Zotero/storage/MC6GASRA/9168-detect-circles-with-various-radii-in-grayscale-image-via-hough-transform.html}
}

@article{canny_computational_1986,
  title = {A {{Computational Approach}} to {{Edge Detection}}},
  volume = {PAMI-8},
  issn = {0162-8828},
  abstract = {This paper describes a computational approach to edge detection. The success of the approach depends on the definition of a comprehensive set of goals for the computation of edge points. These goals must be precise enough to delimit the desired behavior of the detector while making minimal assumptions about the form of the solution. We define detection and localization criteria for a class of edges, and present mathematical forms for these criteria as functionals on the operator impulse response. A third criterion is then added to ensure that the detector has only one response to a single edge. We use the criteria in numerical optimization to derive detectors for several common image features, including step edges. On specializing the analysis to step edges, we find that there is a natural uncertainty principle between detection and localization performance, which are the two main goals. With this principle we derive a single operator shape which is optimal at any scale. The optimal detector has a simple approximate implementation in which edges are marked at maxima in gradient magnitude of a Gaussian-smoothed image. We extend this simple detector using operators of several widths to cope with different signal-to-noise ratios in the image. We present a general method, called feature synthesis, for the fine-to-coarse integration of information from operators at different scales. Finally we show that step edge detector performance improves considerably as the operator point spread function is extended along the edge.},
  number = {6},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  doi = {10.1109/TPAMI.1986.4767851},
  author = {Canny, J.},
  month = nov,
  year = {1986},
  keywords = {Signal synthesis,Image edge detection,\#C,image processing,Signal to noise ratio,Machine vision,Detectors,feature extraction,Uncertainty,edge detection,Performance analysis,Gaussian approximation,multiscale image analysis,Shape measurement},
  pages = {679-698},
  file = {/home/reconmaster/cloud/medical_physics/zotero/canny_computational_1986.pdf;/home/reconmaster/Zotero/storage/Q4WBTINA/articleDetails.html}
}

@article{bao_canny_2005,
  title = {Canny Edge Detection Enhancement by Scale Multiplication},
  volume = {27},
  issn = {0162-8828},
  abstract = {The technique of scale multiplication is analyzed in the framework of Canny edge detection. A scale multiplication function is defined as the product of the responses of the detection filter at two scales. Edge maps are constructed as the local maxima by thresholding the scale multiplication results. The detection and localization criteria of the scale multiplication are derived. At a small loss in the detection criterion, the localization criterion can be much improved by scale multiplication. The product of the two criteria for scale multiplication is greater than that for a single scale, which leads to better edge detection performance. Experimental results are presented.},
  number = {9},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  doi = {10.1109/TPAMI.2005.173},
  author = {Bao, P. and Zhang, Lei and Wu, Xiaolin},
  month = sep,
  year = {2005},
  keywords = {Algorithms,Signal synthesis,Gaussian processes,Image edge detection,Imaging; Three-Dimensional,Image Interpretation; Computer-Assisted,Signal Processing; Computer-Assisted,Image Enhancement,Information Storage and Retrieval,Pattern Recognition; Automated,Subtraction Technique,Detectors,Filtering,Artificial Intelligence,edge detection,Noise reduction,image enhancement,Canny edge detection enhancement,detection criterion,detection filter,edge maps,Finite impulse response filter,Gaussian noise,Index Terms- Edge detection,localization criterion,multiscale analysis.,Noise robustness,scale multiplication,Signal detection},
  pages = {1485-1490},
  file = {/home/reconmaster/Zotero/storage/UM2HCN7H/Bao et al. - 2005 - Canny edge detection enhancement by scale multipli.pdf;/home/reconmaster/Zotero/storage/JZ9G232H/1471712.html}
}

@incollection{canny_computational_1987,
  address = {{San Francisco (CA)}},
  title = {A {{Computational Approach}} to {{Edge Detection}}},
  isbn = {978-0-08-051581-6},
  abstract = {This paper describes a computational approach to edge detection. The success of the approach depends on the definition of a comprehensive set of goals for the computation of edge points. These goals must be precise enough to delimit the desired behavior of the detector while making minimal assumptions about the form of the solution. We define detection and localization criteria for a class of edges, and present mathematical forms for these criteria as functionals on the operator impulse response. A third criterion is then added to ensure that the detector has only one response to a single edge. We use the criteria in numerical optimization to derive detectors for several common image features, including step edges. On specializing the analysis to step edges, we find that there is a natural uncertainty principle between detection and localization performance, which are the two main goals. With this principle we derive a single operator shape which is optimal at any scale. The optimal detector has a simple approximate implementation in which edges are marked at maxima in gradient magnitude of a Gaussian-smoothed image. We extend this simple detector using operators of several widths to cope with different signal-to-noise ratios in the image. We present a general method, called feature synthesis, for the fine-to-coarse integration of information from operators at different scales. Finally we show that step edge detector performance improves considerably as the operator point spread function is extended along the edge. This detection scheme uses several elongated operators at each point, and the directional operator outputs are integrated with the gradient maximum detector.},
  booktitle = {Readings in {{Computer Vision}}},
  publisher = {{Morgan Kaufmann}},
  doi = {10.1016/B978-0-08-051581-6.50024-6},
  author = {Canny, JOHN},
  year = {1987},
  pages = {184-203},
  file = {/home/reconmaster/Zotero/storage/8E6II6YA/B9780080515816500246.html}
}


